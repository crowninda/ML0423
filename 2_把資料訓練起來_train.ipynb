{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "2.把資料訓練起來 train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KYaoTUrNDGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "24a56ef3-a135-4ff2-cefb-e722f92fc9f9"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw5nhJlH3Vjf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "82282106-9fa1-48e9-c173-ea0a34a624c9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSku6gwq2mHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "552869f7-22eb-418a-9177-46f8a90e8340"
      },
      "source": [
        "import sys\n",
        "FOLDER_PATH = '/content/drive/My Drive/yolo/keras-yolo3-blood-cell'\n",
        "sys.path.append(FOLDER_PATH)\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras.layers import Input, Lambda\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
        "from yolo3.utils import get_random_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbMaI_Nbmg1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FOLDER_PATH = '/content/drive/My Drive/yolo'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyAHLQiJ2mHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''loads the classes'''\n",
        "def get_classes(classes_path):\n",
        "    with open(classes_path) as f:\n",
        "        class_names = f.readlines()\n",
        "    class_names = [c.strip() for c in class_names]\n",
        "    return class_names\n",
        "\n",
        "'''loads the anchors from a file'''\n",
        "def get_anchors(anchors_path):\n",
        "    with open(anchors_path) as f:\n",
        "        anchors = f.readline()\n",
        "    anchors = [float(x) for x in anchors.split(',')]\n",
        "    return np.array(anchors).reshape(-1, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzsB6f8m2mHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(input_shape, anchors, num_classes, load_pretrained=False, freeze_body=2, weights_path=''):\n",
        "    '''create the training model'''\n",
        "    K.clear_session() # get a new session\n",
        "    image_input = Input(shape=(None, None, 3))\n",
        "    h, w = input_shape\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
        "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
        "\n",
        "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
        "    print(f'Create YOLOv3 model with {num_anchors} anchors and {num_classes} classes.')\n",
        "\n",
        "    if load_pretrained:\n",
        "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "        print('Load weights {}.'.format(weights_path))\n",
        "        if freeze_body in [1, 2]:\n",
        "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
        "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
        "            for i in range(num): model_body.layers[i].trainable = False\n",
        "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
        "\n",
        "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
        "        [*model_body.output, *y_true])\n",
        "    model = Model([model_body.input, *y_true], model_loss)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3aVW9eG2mHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''data generator for fit_generator'''\n",
        "\n",
        "def data_generator(folder_path, annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    n = len(annotation_lines)\n",
        "    i = 0\n",
        "    while True:\n",
        "        image_data = []\n",
        "        box_data = []\n",
        "        for b in range(batch_size):\n",
        "            if i==0:\n",
        "                np.random.shuffle(annotation_lines)\n",
        "            image, box = get_random_data(folder_path, annotation_lines[i], input_shape, random=True)\n",
        "            image_data.append(image)\n",
        "            box_data.append(box)\n",
        "            i = (i+1) % n\n",
        "        image_data = np.array(image_data)\n",
        "        box_data = np.array(box_data)\n",
        "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
        "        yield [image_data, *y_true], np.zeros(batch_size)\n",
        "\n",
        "def data_generator_wrapper(folder_path, annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    n = len(annotation_lines)\n",
        "    if n==0 or batch_size<=0: return None\n",
        "    return data_generator(folder_path, annotation_lines, batch_size, input_shape, anchors, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIlKwFkK2mHb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f854c49-2243-4cd9-ceb8-86d251e1e93c"
      },
      "source": [
        "annotation_path = os.path.join(FOLDER_PATH, 'anno_beach_0714.txt')\n",
        "classes_path = os.path.join(FOLDER_PATH, '第一次影像蒐集/海廢lable/class/predefined_classes.txt')\n",
        "anchors_path = os.path.join(FOLDER_PATH, 'keras-yolo3-blood-cell/model_data/yolo_anchors.txt')\n",
        "class_names = get_classes(classes_path)\n",
        "num_classes = len(class_names)\n",
        "anchors = get_anchors(anchors_path)\n",
        "\n",
        "input_shape = (416,416) # multiple of 32, hw\n",
        "\n",
        "model = create_model(input_shape, anchors, num_classes, load_pretrained=False, freeze_body=2) # make sure you know what you freeze\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
        "\n",
        "checkpoint = ModelCheckpoint('/content/drive/My Drive/yolo/train_epoch_record/ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
        "    monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "val_split = 0.1\n",
        "with open(annotation_path) as f:\n",
        "    lines = f.readlines()\n",
        "np.random.seed(5566)\n",
        "np.random.shuffle(lines)\n",
        "np.random.seed(None)\n",
        "num_val = int(len(lines)*val_split)\n",
        "num_train = len(lines) - num_val\n",
        "\n",
        "# Train with frozen layers first, to get a stable loss.\n",
        "# Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
        "if True:\n",
        "    model.compile(optimizer=Adam(lr=1e-3), loss={\n",
        "        # use custom yolo_loss Lambda layer.\n",
        "        'yolo_loss': lambda y_true, y_pred: y_pred})\n",
        "\n",
        "    batch_size = 4\n",
        "    print(f'Train on {num_train} samples, val on {num_val} samples, with batch size {batch_size}.')\n",
        "    model.fit_generator(data_generator_wrapper(FOLDER_PATH, lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "            steps_per_epoch=max(1, num_train//batch_size),\n",
        "            validation_data=data_generator_wrapper(FOLDER_PATH, lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
        "            validation_steps=max(1, num_val//batch_size),\n",
        "            epochs=50,\n",
        "            initial_epoch=0,\n",
        "            callbacks=[checkpoint])\n",
        "#     model.save_weights('trained_weights_stage_1.h5')\n",
        "\n",
        "# Unfreeze and continue training, to fine-tune.\n",
        "# Train longer if the result is not good.\n",
        "if True:\n",
        "    for i in range(len(model.layers)):\n",
        "        model.layers[i].trainable = True\n",
        "    model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
        "    print('Unfreeze all of the layers.')\n",
        "\n",
        "    batch_size = 4 # note that more GPU memory is required after unfreezing the body\n",
        "    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        "    model.fit_generator(data_generator_wrapper(FOLDER_PATH, lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "        steps_per_epoch=max(1, num_train//batch_size),\n",
        "        validation_data=data_generator_wrapper(FOLDER_PATH, lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
        "        validation_steps=max(1, num_val//batch_size),\n",
        "        epochs=100,\n",
        "        initial_epoch=50,\n",
        "        callbacks=[checkpoint, reduce_lr, early_stopping])\n",
        "#     model.save_weights('trained_weights_final.h5')\n",
        "\n",
        "# Further training if needed."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Create YOLOv3 model with 9 anchors and 10 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3170: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 778 samples, val on 86 samples, with batch size 4.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/50\n",
            "194/194 [==============================] - 441s 2s/step - loss: 517.2635 - val_loss: 107.6394\n",
            "Epoch 2/50\n",
            "194/194 [==============================] - 84s 435ms/step - loss: 95.5855 - val_loss: 77.3835\n",
            "Epoch 3/50\n",
            "194/194 [==============================] - 85s 437ms/step - loss: 86.1072 - val_loss: 78.7530\n",
            "Epoch 4/50\n",
            "194/194 [==============================] - 83s 430ms/step - loss: 88.7879 - val_loss: 74.6198\n",
            "Epoch 5/50\n",
            "194/194 [==============================] - 85s 437ms/step - loss: 82.9977 - val_loss: 38.3616\n",
            "Epoch 6/50\n",
            "194/194 [==============================] - 85s 440ms/step - loss: 79.1641 - val_loss: 42.0381\n",
            "Epoch 7/50\n",
            "194/194 [==============================] - 87s 446ms/step - loss: 78.8530 - val_loss: 51.4497\n",
            "Epoch 8/50\n",
            "194/194 [==============================] - 86s 445ms/step - loss: 76.1505 - val_loss: 45.7477\n",
            "Epoch 9/50\n",
            "194/194 [==============================] - 86s 445ms/step - loss: 72.4133 - val_loss: 33.8042\n",
            "Epoch 10/50\n",
            "194/194 [==============================] - 87s 449ms/step - loss: 72.7498 - val_loss: 30.7711\n",
            "Epoch 11/50\n",
            "194/194 [==============================] - 86s 443ms/step - loss: 72.3695 - val_loss: 81.6735\n",
            "Epoch 12/50\n",
            "194/194 [==============================] - 86s 444ms/step - loss: 67.2323 - val_loss: 54.3239\n",
            "Epoch 13/50\n",
            "194/194 [==============================] - 86s 443ms/step - loss: 68.4987 - val_loss: 36.4939\n",
            "Epoch 14/50\n",
            "194/194 [==============================] - 87s 448ms/step - loss: 67.4747 - val_loss: 40.0410\n",
            "Epoch 15/50\n",
            "194/194 [==============================] - 86s 443ms/step - loss: 64.3830 - val_loss: 56.1679\n",
            "Epoch 16/50\n",
            "194/194 [==============================] - 87s 447ms/step - loss: 63.7352 - val_loss: 52.9052\n",
            "Epoch 17/50\n",
            "194/194 [==============================] - 87s 446ms/step - loss: 65.6102 - val_loss: 44.6037\n",
            "Epoch 18/50\n",
            "194/194 [==============================] - 88s 452ms/step - loss: 83.3750 - val_loss: 116.2567\n",
            "Epoch 19/50\n",
            "194/194 [==============================] - 87s 448ms/step - loss: 81.9222 - val_loss: 50.0091\n",
            "Epoch 20/50\n",
            "194/194 [==============================] - 87s 446ms/step - loss: 73.8644 - val_loss: 60.3415\n",
            "Epoch 21/50\n",
            "194/194 [==============================] - 87s 447ms/step - loss: 71.1568 - val_loss: 51.6385\n",
            "Epoch 22/50\n",
            "194/194 [==============================] - 87s 447ms/step - loss: 71.0620 - val_loss: 43.6436\n",
            "Epoch 23/50\n",
            "194/194 [==============================] - 86s 445ms/step - loss: 66.0738 - val_loss: 53.8533\n",
            "Epoch 24/50\n",
            "194/194 [==============================] - 86s 445ms/step - loss: 66.1911 - val_loss: 58.4424\n",
            "Epoch 25/50\n",
            "194/194 [==============================] - 87s 448ms/step - loss: 65.8770 - val_loss: 93.4811\n",
            "Epoch 26/50\n",
            "194/194 [==============================] - 87s 447ms/step - loss: 67.0161 - val_loss: 52.1315\n",
            "Epoch 27/50\n",
            "194/194 [==============================] - 86s 445ms/step - loss: 63.4182 - val_loss: 31.3115\n",
            "Epoch 28/50\n",
            "194/194 [==============================] - 88s 451ms/step - loss: 62.0117 - val_loss: 41.7998\n",
            "Epoch 29/50\n",
            "194/194 [==============================] - 86s 445ms/step - loss: 64.4571 - val_loss: 56.5290\n",
            "Epoch 30/50\n",
            "194/194 [==============================] - 86s 445ms/step - loss: 62.9256 - val_loss: 25.2389\n",
            "Epoch 31/50\n",
            "194/194 [==============================] - 86s 446ms/step - loss: 60.1496 - val_loss: 72.9386\n",
            "Epoch 32/50\n",
            "194/194 [==============================] - 86s 444ms/step - loss: 60.5435 - val_loss: 36.6542\n",
            "Epoch 33/50\n",
            "194/194 [==============================] - 86s 445ms/step - loss: 59.4809 - val_loss: 79.9222\n",
            "Epoch 34/50\n",
            "194/194 [==============================] - 86s 443ms/step - loss: 58.5021 - val_loss: 39.0755\n",
            "Epoch 35/50\n",
            "194/194 [==============================] - 86s 444ms/step - loss: 59.2286 - val_loss: 81.7852\n",
            "Epoch 36/50\n",
            "194/194 [==============================] - 87s 446ms/step - loss: 57.5717 - val_loss: 73.3452\n",
            "Epoch 37/50\n",
            "194/194 [==============================] - 86s 444ms/step - loss: 63.4938 - val_loss: 31.5270\n",
            "Epoch 38/50\n",
            "194/194 [==============================] - 87s 446ms/step - loss: 61.1649 - val_loss: 79.8795\n",
            "Epoch 39/50\n",
            "194/194 [==============================] - 87s 447ms/step - loss: 67.3744 - val_loss: 23.4041\n",
            "Epoch 40/50\n",
            "194/194 [==============================] - 87s 449ms/step - loss: 60.1440 - val_loss: 24.1300\n",
            "Epoch 41/50\n",
            "194/194 [==============================] - 87s 446ms/step - loss: 59.0069 - val_loss: 80.3044\n",
            "Epoch 42/50\n",
            "194/194 [==============================] - 86s 445ms/step - loss: 57.5909 - val_loss: 39.8964\n",
            "Epoch 43/50\n",
            "194/194 [==============================] - 87s 447ms/step - loss: 57.1414 - val_loss: 68.6791\n",
            "Epoch 44/50\n",
            "194/194 [==============================] - 87s 448ms/step - loss: 54.1619 - val_loss: 30.2120\n",
            "Epoch 45/50\n",
            "194/194 [==============================] - 87s 446ms/step - loss: 56.4577 - val_loss: 102.8703\n",
            "Epoch 46/50\n",
            "194/194 [==============================] - 87s 448ms/step - loss: 53.3786 - val_loss: 30.8738\n",
            "Epoch 47/50\n",
            "194/194 [==============================] - 86s 443ms/step - loss: 54.1868 - val_loss: 43.3553\n",
            "Epoch 48/50\n",
            "194/194 [==============================] - 87s 449ms/step - loss: 55.3382 - val_loss: 31.5197\n",
            "Epoch 49/50\n",
            "194/194 [==============================] - 87s 449ms/step - loss: 62.9911 - val_loss: 96.4629\n",
            "Epoch 50/50\n",
            "194/194 [==============================] - 87s 448ms/step - loss: 59.8684 - val_loss: 52.2621\n",
            "Unfreeze all of the layers.\n",
            "Train on 778 samples, val on 86 samples, with batch size 4.\n",
            "Epoch 51/100\n",
            "194/194 [==============================] - 100s 513ms/step - loss: 54.6859 - val_loss: 95.2441\n",
            "Epoch 52/100\n",
            "194/194 [==============================] - 86s 445ms/step - loss: 53.6176 - val_loss: 77.7088\n",
            "Epoch 53/100\n",
            "194/194 [==============================] - 87s 450ms/step - loss: 52.0291 - val_loss: 39.2132\n",
            "Epoch 54/100\n",
            "194/194 [==============================] - 87s 448ms/step - loss: 52.1788 - val_loss: 30.2017\n",
            "Epoch 55/100\n",
            "194/194 [==============================] - 87s 449ms/step - loss: 50.3928 - val_loss: 56.0378\n",
            "Epoch 56/100\n",
            "194/194 [==============================] - 86s 445ms/step - loss: 51.3067 - val_loss: 93.1261\n",
            "Epoch 57/100\n",
            "194/194 [==============================] - 87s 449ms/step - loss: 50.7439 - val_loss: 30.7870\n",
            "\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 58/100\n",
            "194/194 [==============================] - 86s 442ms/step - loss: 50.2429 - val_loss: 19.4051\n",
            "Epoch 59/100\n",
            "194/194 [==============================] - 87s 447ms/step - loss: 50.2720 - val_loss: 22.6049\n",
            "Epoch 60/100\n",
            "194/194 [==============================] - 87s 450ms/step - loss: 48.7979 - val_loss: 28.6654\n",
            "Epoch 61/100\n",
            "194/194 [==============================] - 87s 448ms/step - loss: 48.4625 - val_loss: 13.1173\n",
            "Epoch 62/100\n",
            "194/194 [==============================] - 87s 448ms/step - loss: 50.0326 - val_loss: 44.0682\n",
            "Epoch 63/100\n",
            "194/194 [==============================] - 87s 448ms/step - loss: 48.6198 - val_loss: 37.5171\n",
            "Epoch 64/100\n",
            "194/194 [==============================] - 87s 447ms/step - loss: 48.1297 - val_loss: 40.0577\n",
            "\n",
            "Epoch 00064: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Epoch 65/100\n",
            "194/194 [==============================] - 87s 451ms/step - loss: 50.0958 - val_loss: 26.1988\n",
            "Epoch 66/100\n",
            "194/194 [==============================] - 86s 446ms/step - loss: 48.1130 - val_loss: 25.0419\n",
            "Epoch 67/100\n",
            "194/194 [==============================] - 87s 449ms/step - loss: 48.3764 - val_loss: 28.4050\n",
            "\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "Epoch 68/100\n",
            "194/194 [==============================] - 87s 448ms/step - loss: 49.7411 - val_loss: 39.7498\n",
            "Epoch 69/100\n",
            "194/194 [==============================] - 87s 451ms/step - loss: 48.9628 - val_loss: 22.7128\n",
            "Epoch 70/100\n",
            "194/194 [==============================] - 88s 453ms/step - loss: 46.8693 - val_loss: 26.4003\n",
            "\n",
            "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
            "Epoch 71/100\n",
            "194/194 [==============================] - 87s 451ms/step - loss: 49.1484 - val_loss: 36.6543\n",
            "Epoch 00071: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1Ju4Zah2mHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}